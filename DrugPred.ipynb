{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fc29e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Data\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv(r'./train/features.csv')\n",
    "\n",
    "X_test = pd.read_csv(r'./test/features.csv')\n",
    "\n",
    "y_train = pd.read_csv(r'./train/labels.csv')\n",
    "\n",
    "y_test = pd.read_csv(r'./test/labels.csv')\n",
    "\n",
    "del X_train['Unnamed: 0']\n",
    "del X_test['Unnamed: 0']\n",
    "\n",
    "del y_train['Unnamed: 0']\n",
    "del y_test['Unnamed: 0']\n",
    "\n",
    "X_train = X_train.values.tolist()\n",
    "X_test = X_test.values.tolist()\n",
    "y_train = y_train.values.tolist()\n",
    "y_test = y_test.values.tolist()\n",
    "\n",
    "\n",
    "y_train = [it[0] for it in y_train]\n",
    "y_test = [it[0] for it in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfb68f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1447\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7447a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8907f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for i in y_train:\n",
    "    cont+=i\n",
    "for j in y_test:\n",
    "    cont+=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa02f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83cb91e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1447+161-668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85966ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9192546583850931\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_svm = svm.SVC(probability=True)  \n",
    "\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "probabilities_svm = model_svm.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 计算分类准确率\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"ACC:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aea7b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/model_svm.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_svm, './model/model_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20d2f30",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      8\u001b[0m clf_DecisionTreeClassifier \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclf_DecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m y_pred_DecisionTreeClassifier \u001b[38;5;241m=\u001b[39m clf_DecisionTreeClassifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     17\u001b[0m probabilities_DecisionTreeClassifier \u001b[38;5;241m=\u001b[39m clf_DecisionTreeClassifier\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classificationMetalIons\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classificationMetalIons\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\classificationMetalIons\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "clf_DecisionTreeClassifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "clf_DecisionTreeClassifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_DecisionTreeClassifier = clf_DecisionTreeClassifier.predict(X_test)\n",
    "\n",
    "\n",
    "probabilities_DecisionTreeClassifier = clf_DecisionTreeClassifier.predict_proba(X_test)\n",
    "\n",
    "accuracy_DecisionTreeClassifier = accuracy_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "print(\"ACC：\", accuracy_DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82261558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf_DecisionTreeClassifier, './model/clf_DecisionTreeClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89883e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model_RandomForestClassifier = RandomForestClassifier()\n",
    "\n",
    "model_RandomForestClassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_RandomForestClassifier = model_RandomForestClassifier.predict(X_test)\n",
    "\n",
    "probabilities_RandomForestClassifier = model_RandomForestClassifier.predict_proba(X_test)\n",
    "\n",
    "accuracy_RandomForestClassifier = accuracy_score(y_test, y_pred_RandomForestClassifier)\n",
    "print(\"ACC：\", accuracy_RandomForestClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd734ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_RandomForestClassifier, './model/model_RandomForestClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6957ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_KNN = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_KNN)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31995a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(knn, './model/knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(256, 64), max_iter=1100)  \n",
    "\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = model_mlp.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "probabilities_mlp = model_mlp.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_mlp, './model/model_mlp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09497c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model_catboost = CatBoostClassifier(iterations=1500, depth=3, learning_rate=0.04, loss_function='Logloss')\n",
    "\n",
    "model_catboost.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "\n",
    "y_pred_prob_catboost = model_catboost.predict(X_test, prediction_type='Probability')[:, 1]\n",
    "probabilities_catboost = model_catboost.predict(X_test, prediction_type='Probability')\n",
    "y_pred_catboost = [1 if pred > 0.5 else 0 for pred in y_pred_prob_catboost] \n",
    "\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "print(f'Accuracy: {accuracy_catboost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model_catboost, './model/model_catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a66e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "#     'max_depth': 3,                  \n",
    "    'learning_rate': 0.03,           \n",
    "    'n_estimators': 1200         \n",
    "}\n",
    "\n",
    "\n",
    "model_xgboost = xgb.XGBClassifier(**params)\n",
    "\n",
    "model_xgboost.fit(X_train, y_train)\n",
    "\n",
    "probabilities_xgboost = model_xgboost.predict_proba(X_test)\n",
    "\n",
    "\n",
    "y_pred_xgboost = model_xgboost.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_xgboost)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_xgboost, './model/model_xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c11ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probabilities_svm = model_svm.predict_proba(X_test)\n",
    "probabilities_xgboost = model_xgboost.predict_proba(X_test)\n",
    "probabilities_catboost = model_catboost.predict_proba(X_test)\n",
    "\n",
    "probabilities_mlp = model_mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d32c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feture_train = []\n",
    "for i in range(len(probabilities_svm)):\n",
    "    \n",
    "    class_feture_train.append(probabilities_svm[i].tolist() + probabilities_xgboost[i].tolist() + probabilities_catboost[i].tolist()+ probabilities_mlp[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_feture_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy as cp\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_vote, X_test_vote, y_train_vote, y_test_vote = train_test_split(class_feture_train, y_test, test_size=0.6, random_state=42)\n",
    "\n",
    "\n",
    "model_vete = svm.SVC(probability=True) \n",
    "\n",
    "model_vete.fit(X_train_vote, y_train_vote)\n",
    "\n",
    "y_pred_vote = model_vete.predict(X_test_vote)\n",
    "\n",
    "probabilities_vote = model_vete.predict_proba(X_test_vote)\n",
    "\n",
    "accuracy_vote = accuracy_score(y_test_vote, y_pred_vote)\n",
    "print(\"ACC:\", accuracy_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60536ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getFprTpr(y_test,y_scores,thresholds):\n",
    "\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        tp = np.sum((y_pred == 1) & (y_test == 1))\n",
    "        fn = np.sum((y_pred == 0) & (y_test == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_test == 0))\n",
    "        tn = np.sum((y_pred == 0) & (y_test == 0))\n",
    "\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    return fpr_list,tpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9892006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecisionRecall(y_test, y_scores, thresholds):\n",
    "\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        tp = np.sum((y_pred == 1) & (y_test == 1))\n",
    "        fn = np.sum((y_pred == 0) & (y_test == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_test == 0))\n",
    "        tn = np.sum((y_pred == 0) & (y_test == 0))\n",
    "#         print(tp,fp)\n",
    "        if tp + fp == 0 or tp + fn == 0:\n",
    "            continue\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    return precision_list, recall_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"colorblind\", 7)\n",
    "thresholds = np.arange(0, 1.03, 0.03)\n",
    "\n",
    "precision1, recall1 = getPrecisionRecall(np.array(y_test_vote), probabilities_vote[:,1],thresholds)\n",
    "\n",
    "\n",
    "prc_auc1 = auc(recall1, precision1)\n",
    "\n",
    "precision2, recall2 = getPrecisionRecall(np.array(y_test), probabilities_svm[:,1],thresholds)\n",
    "\n",
    "prc_auc2 = auc(recall2, precision2)\n",
    "\n",
    "precision3, recall3 = getPrecisionRecall(np.array(y_test), probabilities_DecisionTreeClassifier[:,1],thresholds)\n",
    "\n",
    "prc_auc3 = auc(recall3, precision3)\n",
    "\n",
    "precision4, recall4 = getPrecisionRecall(np.array(y_test), probabilities_RandomForestClassifier[:,1],thresholds)\n",
    "\n",
    "prc_auc4 = auc(recall4, precision4)\n",
    "\n",
    "precision5, recall5 = getPrecisionRecall(np.array(y_test), probabilities_xgboost[:,1],thresholds)\n",
    "\n",
    "prc_auc5 = auc(recall5, precision5)\n",
    "\n",
    "precision6, recall6 = getPrecisionRecall(np.array(y_test), probabilities_mlp[:,1],thresholds)\n",
    "\n",
    "prc_auc6 = auc(recall6, precision6)\n",
    "\n",
    "\n",
    "precision7, recall7 = getPrecisionRecall(np.array(y_test), probabilities_catboost[:,1],thresholds)\n",
    "\n",
    "prc_auc7 = auc(recall7, precision7)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall1,precision1,  lw=2, label=f'XLC-S-MIBP(area = {prc_auc1:.4f})', color=colors[0])\n",
    "plt.plot(recall2, precision2, lw=2, label=f'SVM(area = {prc_auc2:.4f})', color=colors[1])\n",
    "\n",
    "plt.plot(recall4, precision4, lw=2, label=f'RF(area = {prc_auc4:.4f})', color=colors[3])\n",
    "plt.plot(recall5, precision5, lw=2, label=f'xgboost(area = {prc_auc5:.4f})', color=colors[4])\n",
    "plt.plot(recall6, precision6, lw=2, label=f'NN(area = {prc_auc6:.4f})', color=colors[5])\n",
    "plt.plot(recall7, precision7, lw=2, label=f'catboost(area = {prc_auc7:.4f})', color=colors[6])\n",
    "\n",
    "\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "plt.ylabel('Precision', fontsize=15)\n",
    "plt.title('Precision-Recall Curve', fontsize=18)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"colorblind\", 7)\n",
    "\n",
    "thresholds = np.arange(0, 1.03, 0.03)\n",
    "\n",
    "fpr1, tpr1 = getFprTpr(np.array(y_test_vote), probabilities_vote[:,1], thresholds)\n",
    "\n",
    "\n",
    "\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpr2, tpr2= getFprTpr(np.array(y_test), probabilities_svm[:,1], thresholds)\n",
    "\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "\n",
    "fpr3, tpr3, thresholds3 = roc_curve(y_test, probabilities_DecisionTreeClassifier[:,1])\n",
    "\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "fpr4, tpr4, thresholds4 = roc_curve(y_test, probabilities_RandomForestClassifier[:,1])\n",
    "\n",
    "roc_auc4 = auc(fpr4, tpr4)\n",
    "\n",
    "\n",
    "fpr5, tpr5 = getFprTpr(np.array(y_test), probabilities_xgboost[:,1], thresholds)\n",
    "\n",
    "roc_auc5 = auc(fpr5, tpr5)\n",
    "\n",
    "\n",
    "fpr6, tpr6 = getFprTpr(np.array(y_test), probabilities_mlp[:,1], thresholds)\n",
    "\n",
    "roc_auc6 = auc(fpr6, tpr6)\n",
    "\n",
    "\n",
    "fpr7, tpr7 = getFprTpr(np.array(y_test), probabilities_catboost[:,1], thresholds)\n",
    "\n",
    "roc_auc7 = auc(fpr7, tpr7)\n",
    "\n",
    "plt.rcParams['font.size'] = 15 \n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr1, tpr1, lw=2, label=f'XLC-S-MIBP(auc = {roc_auc1:.4f})', color=colors[0])\n",
    "plt.plot(fpr2, tpr2, lw=2, label=f'SVM(auc = {roc_auc2:.4f})', color=colors[1])\n",
    "plt.plot(fpr3, tpr3, lw=2, label=f'DT(auc = {roc_auc3:.4f})', color=colors[2])\n",
    "plt.plot(fpr4, tpr4, lw=2, label=f'RF(auc = {roc_auc4:.4f})', color=colors[3])\n",
    "plt.plot(fpr5, tpr5, lw=2, label=f'xgboost(auc = {roc_auc5:.4f})', color=colors[4])\n",
    "plt.plot(fpr6, tpr6, lw=2, label=f'NN(auc = {roc_auc6:.4f})', color=colors[5])\n",
    "plt.plot(fpr7, tpr7, lw=2, label=f'catboost(auc = {roc_auc7:.4f})', color=colors[6])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=18)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [1, 0, 1, 2, 0, 1, 2, 3, 3, 2]\n",
    "predicted_labels = [1, 0, 2, 2, 0, 1, 3, 3, 2, 2]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04394787",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "classes = ['Non-Drug','Drug']\n",
    "sns.heatmap([[63,2],[1,31]], annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes,annot_kws={\"size\": 14})\n",
    "plt.xlabel('Predicted Labels', fontsize=15)\n",
    "plt.ylabel('True Labels', fontsize=15)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "precision_vote = precision_score(y_test_vote, y_pred_vote)\n",
    "recall_vote = recall_score(y_test_vote, y_pred_vote)\n",
    "f1_vote = f1_score(y_test_vote, y_pred_vote)\n",
    "mcc_vote = matthews_corrcoef(y_test_vote, y_pred_vote)\n",
    "print('mymodel')\n",
    "print(\"Precision: {:.4f}\".format(precision_vote))\n",
    "print(\"Recall: {:.4f}\".format(recall_vote))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_vote))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_vote))\n",
    "\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "mcc_svm = matthews_corrcoef(y_test, y_pred_svm)\n",
    "print('svm')\n",
    "print(\"Precision: {:.4f}\".format(precision_svm))\n",
    "print(\"Recall: {:.4f}\".format(recall_svm))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_svm))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_svm))\n",
    "\n",
    "precision_DecisionTreeClassifier = precision_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "recall_DecisionTreeClassifier = recall_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "f1_DecisionTreeClassifier = f1_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "mcc_DecisionTreeClassifier = matthews_corrcoef(y_test, y_pred_DecisionTreeClassifier)\n",
    "print('DecisionTreeClassifier')\n",
    "print(\"Precision: {:.4f}\".format(precision_DecisionTreeClassifier))\n",
    "print(\"Recall: {:.4f}\".format(recall_DecisionTreeClassifier))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_DecisionTreeClassifier))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_DecisionTreeClassifier))\n",
    "\n",
    "precision_RandomForestClassifier = precision_score(y_test, y_pred_RandomForestClassifier)\n",
    "recall_RandomForestClassifier = recall_score(y_test, y_pred_RandomForestClassifier)\n",
    "f1_RandomForestClassifier = f1_score(y_test, y_pred_RandomForestClassifier)\n",
    "mcc_RandomForestClassifier = matthews_corrcoef(y_test, y_pred_RandomForestClassifier)\n",
    "print('RandomForestClassifier')\n",
    "print(\"Precision: {:.4f}\".format(precision_RandomForestClassifier))\n",
    "print(\"Recall: {:.4f}\".format(recall_RandomForestClassifier))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_RandomForestClassifier))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_RandomForestClassifier))\n",
    "\n",
    "precision_xgboost = precision_score(y_test, y_pred_xgboost)\n",
    "recall_xgboost = recall_score(y_test, y_pred_xgboost)\n",
    "f1_xgboost = f1_score(y_test, y_pred_xgboost)\n",
    "mcc_xgboost = matthews_corrcoef(y_test, y_pred_xgboost)\n",
    "print('xgboost')\n",
    "print(\"Precision: {:.4f}\".format(precision_xgboost))\n",
    "print(\"Recall: {:.4f}\".format(recall_xgboost))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_xgboost))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_xgboost))\n",
    "\n",
    "precision_KNN = precision_score(y_test, y_pred_KNN)\n",
    "recall_KNN = recall_score(y_test, y_pred_KNN)\n",
    "f1_KNN = f1_score(y_test, y_pred_KNN)\n",
    "mcc_KNN = matthews_corrcoef(y_test, y_pred_KNN)\n",
    "print('KNN')\n",
    "print(\"Precision: {:.4f}\".format(precision_KNN))\n",
    "print(\"Recall: {:.4f}\".format(recall_KNN))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_KNN))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_KNN))\n",
    "\n",
    "precision_catboost = precision_score(y_test, y_pred_catboost)\n",
    "recall_catboost = recall_score(y_test, y_pred_catboost)\n",
    "f1_catboost = f1_score(y_test, y_pred_catboost)\n",
    "mcc_catboost = matthews_corrcoef(y_test, y_pred_catboost)\n",
    "print('catboost')\n",
    "print(\"Precision: {:.4f}\".format(precision_catboost))\n",
    "print(\"Recall: {:.4f}\".format(recall_catboost))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_catboost))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_catboost))\n",
    "\n",
    "precision_mlp= precision_score(y_test, y_pred_mlp)\n",
    "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
    "mcc_mlp = matthews_corrcoef(y_test, y_pred_mlp)\n",
    "print('MLP')\n",
    "print(\"Precision: {:.4f}\".format(precision_mlp))\n",
    "print(\"Recall: {:.4f}\".format(recall_mlp))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_mlp))\n",
    "print(\"mcc Score: {:.4f}\".format(mcc_mlp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b7fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416d0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
